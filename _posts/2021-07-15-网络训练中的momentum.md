---
layout: mypost
title: 网络训练中的momentum
categories: [deep-learning]
---

> 转自[@迷上微笑](https://blog.csdn.net/u013989576/article/details/70241121)

训练网络时，通常先对网络的初始权值按照某种分布进行初始化，如：高斯分布。初始化权值操作对最终网络的性能影响比较大，合适的网络初始权值能够使得损失函数在训练过程中的收敛速度更快，从而获得更好的优化结果。但是按照某类分布随机初始化网络权值时，存在一些不确定因素，并不能保证每一次初始化操作都能使得网络的初始权值处在一个合适的状态。不恰当的初始权值可能使得网络的损失函数在训练过程中陷入局部最小值，达不到全局最优的状态。因此，如何消除这种不确定性，是训练深度网络是必须解决的一个问题。 

momentum 动量能够在一定程度上解决这个问题。momentum 动量是依据物理学的势能与动能之间能量转换原理提出来的。当 momentum 动量越大时，其转换为势能的能量也就越大，就越有可能摆脱局部凹域的束缚，进入全局凹域。momentum 动量主要用在权重更新的时候。

一般，神经网络在更新权值时，采用如下公式:
    w = w - learning_rate * dw

引入momentum后，采用如下公式：
    v = mu * v - learning_rate * dw
    w = w + v

其中，v初始化为0，mu是设定的一个超变量，最常见的设定值是0.9。

可以这样理解上式：如果上次的momentum()与这次的负梯度方向是相同的，那这次下降的幅度就会加大，从而加速收敛。